# 典型回答


大模型是怎么来的？其实就是预训练来的，包括现在的GPT、Deepseek这些大模型。通过海量通用数据来训练模型，让模型具有掌握语法、常识和基础语义。



预训练的成本是巨高的，首先需要有海量数据（TB 级），然后还需要极高的算力，进行长时间的模型训练，基本上只有大厂才能玩得起。



而**微调，是在预训练模型的基础上，用特定领域或任务的数据调整模型参数，使其适应具体场景（如医疗问答、法律文本分析）。**

****

相比于预训练，他只需要少量的数据 （MB~GB 级），相对的训练算力也会低很多。**可以说预训练的目的是获得一个通用模型，而微调的目的是获得一个专用模型。**



其实，我们常用的提示词，也可以算作是微调的一种，只不过他相对简单，并不需要调整模型参数来完成，目的是让模型能够更好的回答我们的问题，所以有一种微调叫做Prompt Tuning。



随着模型规模变大，**完整微调（也叫全参）成本也变高**，出现了很多轻量级微调方式：

1. **LoRA（Low-Rank Adaptation）**
2. **PEFT（Parameter-Efficient Fine-Tuning）**
3. **Adapter、Prefix Tuning**
4. **指令微调（Instruction Tuning）**
5. **RLHF（人类反馈强化学习）**



这些方法通常只更新模型的一部分参数，大大减少资源消耗。

