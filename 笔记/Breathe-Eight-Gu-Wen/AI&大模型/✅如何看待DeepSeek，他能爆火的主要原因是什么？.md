# 典型回答


DeepSeek的爆火要从两个方面看，一个是在普通老百姓的视角看，另一个是行业的视角看。



从普通老百姓的视角来看，其实主要给人的感受上有变化是因为他**把思考过程展示了出来**，在DeepSeek之前，其他的模型也都有会自己的思考过程，包括GPT，但是都没有展示出来，而DeepSeek把他展示了出来，在回答问题之前先把自己的思考过程显示出来，让用户知道这个过程是怎么样的。



还有就是**他自身的能力和效果还不错**，而且在中文处理能力上甚至还超越GPT等产品。



从专业的视角来看，行业内能引起这么大的波澜，主要还是他的**成本更低**了，同样的规模的模型，它的成本可以降低到其他模型的1/20，这就能大大的降低对卡（算力）的依赖，而且成本也会更加的低了。在训练费用上只有500多万美元，是GPT-4o十分之一都不到。



还有就是DeepSeek走了一条**开源**的路，DS-R1是开源的。



另外有一个不容忽视的原因，那就是**DeepSeek并没有诞生在传统大厂**，而是诞生在一家来自中国的"小公司"（但是其实幻方做量化也很多年了，也屯了很多卡，只不过不算是互联网大厂），他的崛起，符合"咸鱼翻身，挑战强权"的价值观。



当然，DeepSeek也是有很多**技术创新**的，比如**MoE**（混合专家模型）、**MLA**（多投潜在注意力机制）等。



> DeepSeek采用Transformer+MoE（Mixture of Experts）组合架构，通过动态激活专家网络（如DeepSeek-V3仅激活370亿参数中的部分）显著降低计算资源消耗。其MoE架构引入共享专家与路由专家的分工：共享专家处理通用知识，路由专家针对特定任务优化，提升训练效率与稀疏性。  
此外，通过动态路由机制，模型能根据输入内容自动分配专家资源，实现计算资源的按需分配，综合效率较传统MoE提升30%。
>

