# 典型回答


从1TB的日志中找到搜索量最高的10个关键词，暴力统计肯定也行，但是面试官肯定不想听这个答案。



一个比较典型的方案就是：**哈希分片+大根堆+统计**



所谓的哈希分片，其实是一种典型的分治思想。通过哈希的方式，将相同关键词分配到同一分片，便于统计全局次数。



一般是选择一个相对均匀的哈希函数，比如murmurhash，然后遍历日志文件，将每一个搜索的关键词通过哈希计算分散到不要固定数量的分片文件上（可以大一点，比如几百个，或者1000个都可以）。这样就能确保同一个关键词可以落到同一个分片文件中。



接下来，就可以针对每个文件，逐行读取关键词并使用哈希表统计词频。将统计结果按次数降序排序后保存为中间文件。



因为每个中间文件按次数降序排列的，那么我们就读取每个文件的第一个关键词（即当前分片的最大次数），将其加入最大堆。再使用一个最小堆维护当前前10高频词，初始为空。



然后开始循环执行：

    1. 从最大堆中取出当前全局最大次数候选（记为`关键词K，次数C`）。
    2. 若前10堆（最小堆）未满，直接加入；若已满且`C > 堆顶最小值`，则替换堆顶。
    3. 若`C ≤ 堆顶最小值`且前10堆已满，提前终止（后续关键词次数只会更小）。
    4. 从`K`所在分片文件读取下一个关键词，更新最大堆。



+ 输出结果：最终前10堆中的关键词即为全局Top 10。



# 扩展知识


## 为啥找最大值要用最小堆


[[✅海量数据查找最大的 k 个值，用什么数据结构？]]

