我们的项目中用到了分库分表技术，主要是针对交易订单进行的分库分表，涉及到的方案如下：



## 分库&分表？
### 分库


分库主要解决的问题是并发量高的问题，比较经典的分库场景就是我们在做微服务拆分的时候，就会按照业务的边界，把各个业务的数据从单一的数据拆分开来，分别把订单，物流，商品，会员等数据分别放到单独的数据库中。



### 分表
分表主要解决的问题是数据量大的问题，通过将数据拆分到多个表中，来减少单表的数据量，从而提升查询速度。



## 分表数量
分表数量一般是是数据的存储量 + 每年数据的增长量 * 数据存储的年份 / 2000万 ===>向上取2的幂



比如：存量数据2000万，每年增长1000万，保存20年：

（2000 + 1000 * 20）/ 2000 = 11 ===》 16



## 分表数量
我们的项目中和主流的电商项目保持一致，采用买家ID作为分表字段.



我们知道,电商平台是有买家和卖家的,但是一个大的卖家可能会产生很多订单，比如是这个平台的卖家龙头，他一家店就产生了很多很多数据，如果按卖家ID分表的话，那同一个卖家的很多订单就会分到同一个表中。



那就是有些表的数据量会特别大，但是有些表的数据量又很小，这就是发生了数据倾斜，这个卖家的数据就变成了热点数据，随着时间的增长，就会使得这个卖家的所有操作变得非常缓慢。



![[038c465d-a60b-4426-a231-120cf0cd5984.png]]



但是，买家ID做分表字段就不会出现这个问题，因为不太容易出现一个买家就会出现数据倾斜。



但是需要注意的是，**我们说按照买家Id做分表，保证的是同一个买家的所有订单都在同一张表 ，并不是要给每个买家都单独分配一张表**

****

我们在做分片路由的时候，是可以设置一定的规则的，比如我们想分1024张表，那么我们可以用买家ID或买家ID的hash值对1024取模，结果是000-1023，那么就存储到对应编号的分表中了。

## 分表算法
在分表算法上，我们采用的是 hash 后取模的算法。即针对买家 ID 进行取 hash 值，然后再对总分表数取模。

```java
public class DefaultShardingTableStrategy implements ShardingTableStrategy {

    public DefaultShardingTableStrategy() {
    }

    @Override
    public int getTable(String externalId,int tableCount) {
        int hashCode = externalId.hashCode();
        return (int) Math.abs((long) hashCode) % tableCount;
		
    }
}
```

这里我们还借鉴了hashmap源码的思想做了个小优化

![[5a56d5a2-56a6-4251-b765-d9237df4cec5.png]]



分表算法自定义详见：

[[定义多Key分片算法]]


全局ID

[[全局唯一订单号生成（分布式ID）]]


## 分表后的查询
分表后的查询分两种：

1、带分表键的查询，即买家的订单查询，这种我们就带着 buyerId（或者订单号）去数据库中查询就行了。会自动路由到具体的物理表中进行查询的。

2、不带分表键的查询，这种的话主要是卖家查询、或者平台小二的查询。这种我们就通过 ES 来查询。

