# 背景
基于AB实验逻辑的业务迭代有一个至关重要的前提假设：实验的两个组除了产品本身发生改动的唯一变量以外，其他相关因素，尤其是用户本身的特征都是一样的，即两个人群的用户属性分布是完全均匀的，分流是进行随机分流，具有一定的随机性，所以分流不均匀问题无法完全避免，一般规范的实验流程，实在实验开始前先进行AA校验（现在可以用**预分流**来**提高AA校验的通过率**），来确保分组是同质的后，再进行AB实验，以此来确保AB结果的可信。

Arena实验平台已具备实验AA的能力（实验前AA，实验中AA，回溯AA），做AA实验需要积累几天数据才能得到稳定结果，如果出现指标显著差异需要打散，重新观察，**人力和时间成本都比较大**。

AA不通过常见原因：
1. 样本量不足，方差不稳定。
2. 工具侧对于AA分组的业务策略不一致，AA期间修改过实验配置或者有工程上线。
3. 数仓数据统计逻辑问题。
4. 分组间分流比例不均，分组人群特征人群不均。

问题1， 2， 3需要在产品功能层面引导用户排查并解决，问题4需要实验平台从分流能力层面解决。
# 目标
AA结束以后，由实验平台基于AA期间进组的用户，选取均匀的打散因子，用户可基于该打散因子直接开启AB实验，以此提升AA的效率，节省做实验的时间和人力成本。

这里说的还是很蒙，原来咱们做AA就是为了得到打散因子啊，为什么他什么都没做就说自己提升了AA的效率呢？

根据我的理解，这里的逻辑是这样的：
### 原先
我们如果根据一个打散因子做完实验前AA，如果实验不通过的话，我们是需要去**重新收集数据**，重新进行AA实验，这样就会**十分耽误效率**
### 优化
现在的话，我们如果实验前AA没有成功，那么我们就可以用**相同的数据**，选取**不同的分流因子**，这样利用原数据再次进行实验前AA（这次实验被称为模拟AA），就可以不用重新收集数据，从而**提升AA的效率**。

# 用户交互流程
![[分流均匀性优化.png]]
# 设计思路
## 为什么不在AA前就选取比较好的分流因子
在AA前就选出分流因子，需要业务方完美模拟业务系统的用户过滤条件，提供出流量明细SQL。根据实验后AA1.0的使用情况来看，业务很难提供出能圈选实际进组用户的SQL。
## AA不通过，为何不能自动执行分流因子择优，并打散用户实验，而是由用户在平台触发？
如背景中提到，AA不通过的原因很多，在商分与产品排查过的AA不通过案例中，很多是1、2、3点，即业务方的原因造成的AA不通过，所以建议先引导用户自主排查后，确定是分流不均（流量比例不均、分群特征不均）原因，再发起「分流因子择优」任务。
## 选出优质种子以后，为何不覆盖原来的AA结论，而是新开一个AA结论Tab来展示新Hash因子的结论
因为该功能可用于实验中AA，如果直接覆写AA结论，会造成AA结论使用的数据和实验分析用的数据不一致的问题，所以新开个Tab。
## 「分流因子择优」功能可适用于什么场景?
实验前AA、实验中AA不通过的场景。回溯AA实际使用的业务方较少，目前应该无实际业务使用，且实验后AA的实验AB已经做完了，如果不通过，用户需要重新分配流量比例来做AAB即实验中AA实验。
# 详细设计
## 模块流程图及其说明
![[Pasted image 20251016195354.png]]
## 用指定打散因子进行限流
![[Pasted image 20251016195801.png]]
1. 复用SnapshotCacheVo功能生成指定打散因子的快照缓存。
2. Java SDK需要支持用快照缓存分流，在模拟分流Spark任务中通过SDK模拟出新打散因子的分流结果，将分流结果记录到Hive模拟分流底表中。
3. 在指标计算Spark任务中，将模拟分流底表与用户行为表Join计算指标值。

模拟分流与指标计算拆分为两个Spark任务，只要是为了将模拟分流模块独立出来，若用户需要模拟分流，或者后续建设实验预分流功能时，可直接复用该模块。

**注意：在Spark中分流时，为了避免离线分流的高并发把下游画像服务打挂了，所以离线分流时将不会走画像，而且从分流底表中拿到的分流id，已经是经过画像过滤能命中实验的id。**
## Crane任务执行流程
![[Pasted image 20251016200056.png]]
# 代码分析
## 整体流程
首先从模块流程图开始说起吧，第一步是用户要触发分流因子择优任务，我们会直接关于该模拟AA的实验信息直接保存到数据库中，然后等待Crane触发就可以了，这里要注意的时候，这里要对该模拟AA的任务状态做一层判断。

等到保存到数据库中以后，我们会调用下面这个方法：
![[Pasted image 20251016201051.png]]
他从数据库中先获取没有完成的任务，也就是任务状态为执行中和未开始的状态。将这些数据查询出来。
![[Pasted image 20251016201332.png]]
对应的是这个方法，那么这里其实用到了对于mp的一个魔改，这里的criteria是mp底层用来构建查询对象的一个类，但是这里我们自己设置了一个相同功能的类，然后我们直接添加所有需要查询的状态，就可以获取到未完成的任务。

之后的话，我们要判断一下时间，如果有自定义的时间，我们按照自定义的时间来，如果没有的话，我们的这个定时任务要中午12点之后才会被执行（虽然目前不知道为什么要设置为中午12点之后才能执行），如果可以执行的话，会执行下面的代码逻辑。
![[Pasted image 20251016201734.png]]
我们会在这里对尝试的次数 + 1， 然后设置状态为进行中
接下来就要执行**关键**的步骤
1. 我们要获取当前**时间戳**作为**新的打散因子**，然后新增一个种子择优实验的一次尝试。
2. **生成快照缓存**：这个的作用是什么呢
   ![[Pasted image 20251016202325.png]]
   他在这里对于该实验分流实验做了一次**快照生成**，然后生成**缓存**，**落库**。（其实不是特别理解为什么要在这里做缓存，这个分散因子是什么会特别经常被缓存的变量吗）通过熟悉之后的任务流程，这里的快照作用应该是为了让Spark可以直接通过redis来获取任务，这样效率更高，因为定时任务扫表，这个也是一个比较经常调用的方法。
3. 启动模拟分流Spark任务
   ![[Pasted image 20251016203727.png]]
   这里其实没什么特别好看的，就是获取实验，然后构建Spark执行请求，调用Spark的工具类，在Spark那边来执行，然后接受响应参数就可以了，所以接下来我会通过下面这张图来描述一下Spark经过了什么变化。
   ![[Pasted image 20251016204154.png]]
   在这里我们进行了一些对于数据的处理和结果的计算，并且通过将快照缓存分流，提高了任务的执行效率。并且这里做了一些解耦，将用户分流结果和指标计算相关任务，拆解成两个任务，方便我们日后调用，然后将我们的指标相关直接存到mysql中，将AA分流结果，存储到hive中。

## Crane代码
这里的代码很大一部分都是关于执行中的任务的处理的，也就是我们上面没有分析的另一个分支：
ExpFactorChooseExcuteTask的handleTask
![[Pasted image 20251016205154.png]]
这个分支
![[Pasted image 20251016205216.png]]
进去可以发信到达这个方法，因为同一个任务可以经过多次尝试，所以我们会通过lastTryTask找到最后一次尝试。
![[Pasted image 20251016205306.png]]
同理通过一个example构造了一个mp的一个criteria可以自行注入判断条件，然后我们通过limit 1 和 id desc来保证我们取得是最后的。
我们要知道我们现在的这个逻辑都是围绕着上面写的Crane
![[Pasted image 20251016205611.png]]
也就是我们现在来到了这个上面这个图的逻辑
之后的代码都很重复，基本上就是查询状态，然后判断状态去执行相应的逻辑，如果AA通过，那么择优结束，将打散因子记录下来，通过大象发送消息
![[Pasted image 20251016210202.png]]
这就是整体的逻辑